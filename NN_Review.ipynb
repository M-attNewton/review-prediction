{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resturant Review Sentiment - Neural Network\n",
    "### Matthew Newton\n",
    "* It would be interesting to see how well a neural network can fit to this dataset.\n",
    "* The dataset is structured but also has text as an unstructured datatype.\n",
    "* PyTorch is used to implement the neural network with TfidfVectorizer to create the text features as in the linear model, a word embedding such as Glove or Word2Vec would be more effective but more computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_pickle(\"./cleaned_data/reviews_cleaned_nltk.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train data, cross validation and test data\n",
    "df_review = df_review.dropna()\n",
    "df_review = df_review[:50000] # For testing use subset of total dataset\n",
    "features = ['text', 'title', 'type', 'priceInterval', 'date', 'review_length', 'rest_rating']\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_review[features], df_review['rating'], test_size = 0.30, random_state = 0)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv[features], y_cv, test_size = 0.50, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000) \n",
    "X_train_text = X_train['text'] + ' ' + X_train['title']  # Combine review and title\n",
    "\n",
    "# Fit and transform the review + review title combined text\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text).toarray()\n",
    "\n",
    "# Encode categorical features (Type)\n",
    "le = LabelEncoder()\n",
    "X_train['type'] = le.fit_transform(X_train['type'])\n",
    "# Define a custom transformation function for handling unseen labels\n",
    "def safe_transform(label_encoder, series):\n",
    "    return series.apply(lambda x: label_encoder.transform([x])[0] if x in label_encoder.classes_ else -1)\n",
    "\n",
    "# Normalize numerical features (Price, Date, Review Length, Restaurant Rating)\n",
    "scaler = StandardScaler()\n",
    "X_train[['priceInterval', 'date', 'review_length', 'rest_rating']] = scaler.fit_transform(\n",
    "    X_train[['priceInterval', 'date', 'review_length', 'rest_rating']]\n",
    ")\n",
    "\n",
    "# Concatenate all features (TF-IDF text features, numerical and categorical features)\n",
    "X_train_combined = np.hstack((\n",
    "    X_train_tfidf,  # Text features\n",
    "    X_train[['type', 'priceInterval', 'date', 'review_length', 'rest_rating']].values  # Other features\n",
    "))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values - 1, dtype=torch.long) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Neural Network Model\n",
    "class ReviewNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=5):\n",
    "        super(ReviewNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "#         self.fc4 = nn.Linear(64, output_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 32)\n",
    "        self.fc5 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.softmax = nn.Softmax(dim=output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.fc4(x)\n",
    "        #x = self.softmax\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "input_dim = X_train_combined.shape[1]  # Number of input features\n",
    "model = ReviewNN(input_dim=input_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.2747\n",
      "Epoch 2/50, Loss: 1.2514\n",
      "Epoch 3/50, Loss: 1.1312\n",
      "Epoch 4/50, Loss: 1.0853\n",
      "Epoch 5/50, Loss: 1.0632\n",
      "Epoch 6/50, Loss: 0.9618\n",
      "Epoch 7/50, Loss: 0.7473\n",
      "Epoch 8/50, Loss: 0.8003\n",
      "Epoch 9/50, Loss: 0.9647\n",
      "Epoch 10/50, Loss: 0.9323\n",
      "Epoch 11/50, Loss: 0.7705\n",
      "Epoch 12/50, Loss: 0.7622\n",
      "Epoch 13/50, Loss: 0.6575\n",
      "Epoch 14/50, Loss: 0.7578\n",
      "Epoch 15/50, Loss: 0.5959\n",
      "Epoch 16/50, Loss: 0.7738\n",
      "Epoch 17/50, Loss: 0.9130\n",
      "Epoch 18/50, Loss: 0.7581\n",
      "Epoch 19/50, Loss: 0.7252\n",
      "Epoch 20/50, Loss: 0.9411\n",
      "Epoch 21/50, Loss: 0.7806\n",
      "Epoch 22/50, Loss: 0.7006\n",
      "Epoch 23/50, Loss: 0.8247\n",
      "Epoch 24/50, Loss: 0.9252\n",
      "Epoch 25/50, Loss: 0.8686\n",
      "Epoch 26/50, Loss: 0.7419\n",
      "Epoch 27/50, Loss: 0.6852\n",
      "Epoch 28/50, Loss: 0.8023\n",
      "Epoch 29/50, Loss: 0.9289\n",
      "Epoch 30/50, Loss: 0.7991\n",
      "Epoch 31/50, Loss: 0.7831\n",
      "Epoch 32/50, Loss: 0.7609\n",
      "Epoch 33/50, Loss: 0.7393\n",
      "Epoch 34/50, Loss: 0.7334\n",
      "Epoch 35/50, Loss: 0.8517\n",
      "Epoch 36/50, Loss: 0.8256\n",
      "Epoch 37/50, Loss: 0.8891\n",
      "Epoch 38/50, Loss: 0.7836\n",
      "Epoch 39/50, Loss: 0.6036\n",
      "Epoch 40/50, Loss: 0.7237\n",
      "Epoch 41/50, Loss: 0.6271\n",
      "Epoch 42/50, Loss: 0.8194\n",
      "Epoch 43/50, Loss: 0.6259\n",
      "Epoch 44/50, Loss: 0.7720\n",
      "Epoch 45/50, Loss: 0.7855\n",
      "Epoch 46/50, Loss: 0.7373\n",
      "Epoch 47/50, Loss: 0.5963\n",
      "Epoch 48/50, Loss: 0.8260\n",
      "Epoch 49/50, Loss: 0.7034\n",
      "Epoch 50/50, Loss: 0.6304\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train_model(model, X_train_tensor, y_train_tensor, epochs=10, batch_size=64):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        permutation = torch.randperm(X_train_tensor.size()[0])\n",
    "        \n",
    "        for i in range(0, X_train_tensor.size()[0], batch_size):\n",
    "            indices = permutation[i:i + batch_size]\n",
    "            batch_X, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "train_model(model, X_train_tensor, y_train_tensor, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess validation and test data using the same vectorizer, label encoder, and scaler\n",
    "X_cv_text = X_cv['text'] + ' ' + X_cv['title']\n",
    "X_cv_tfidf = vectorizer.transform(X_cv_text).toarray()\n",
    "X_test_text = X_test['text'] + ' ' + X_test['title']\n",
    "X_test_tfidf = vectorizer.transform(X_test_text).toarray()\n",
    "\n",
    "# Encode restaurant type using the same LabelEncoder\n",
    "X_cv['type'] = safe_transform(le, X_cv['type'])\n",
    "X_test['type'] = safe_transform(le, X_test['type'])\n",
    "\n",
    "# Scale numerical features using the same StandardScaler\n",
    "X_cv[['priceInterval', 'date', 'review_length', 'rest_rating']] = scaler.transform(\n",
    "    X_cv[['priceInterval', 'date', 'review_length', 'rest_rating']]\n",
    ")\n",
    "X_test[['priceInterval', 'date', 'review_length', 'rest_rating']] = scaler.transform(\n",
    "    X_test[['priceInterval', 'date', 'review_length', 'rest_rating']]\n",
    ")\n",
    "\n",
    "# Combine all features for validation and test sets\n",
    "X_cv_combined = np.hstack((\n",
    "    X_cv_tfidf,  # Text features\n",
    "    X_cv[['type', 'priceInterval', 'date', 'review_length', 'rest_rating']].values \n",
    "))\n",
    "\n",
    "X_test_combined = np.hstack((\n",
    "    X_test_tfidf,  # Text features\n",
    "    X_test[['type', 'priceInterval', 'date', 'review_length', 'rest_rating']].values  \n",
    "))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_cv_tensor = torch.tensor(X_cv_combined, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\n",
    "y_cv_tensor = torch.tensor(y_cv.values - 1, dtype=torch.long) \n",
    "y_test_tensor = torch.tensor(y_test.values - 1, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.06%\n",
      "Accuracy: 66.53%\n",
      "Accuracy: 66.36%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_tensor, y_tensor):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():  \n",
    "        outputs = model(X_tensor)\n",
    "        _, predictions = torch.max(outputs, dim=1) \n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = (predictions == y_tensor).sum().item()\n",
    "    total = y_tensor.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n",
    "# Evaluate on training set\n",
    "evaluate_model(model, X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluate_model(model, X_cv_tensor, y_cv_tensor)\n",
    "\n",
    "# Evaluate on test set\n",
    "evaluate_model(model, X_test_tensor, y_test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6653333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       522\n",
      "           1       0.44      0.02      0.04       438\n",
      "           2       0.48      0.43      0.45       803\n",
      "           3       0.54      0.46      0.50      2063\n",
      "           4       0.75      0.89      0.82      3674\n",
      "\n",
      "    accuracy                           0.67      7500\n",
      "   macro avg       0.57      0.52      0.50      7500\n",
      "weighted avg       0.64      0.67      0.64      7500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 417    2   75   26    2]\n",
      " [ 194    8  187   42    7]\n",
      " [  53    6  342  354   48]\n",
      " [   4    2   89  947 1021]\n",
      " [   4    0   19  375 3276]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_cv_tensor)  \n",
    "    _, predictions = torch.max(outputs, dim=1)  \n",
    "\n",
    "# Convert predictions and true labels to NumPy arrays\n",
    "y_cv_true = y_cv_tensor.numpy() \n",
    "y_cv_pred = predictions.numpy() \n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_cv_true, y_cv_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_cv_true, y_cv_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_cv_true, y_cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6636\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       537\n",
      "           1       0.58      0.04      0.07       472\n",
      "           2       0.54      0.44      0.48       847\n",
      "           3       0.52      0.47      0.49      1988\n",
      "           4       0.76      0.88      0.81      3656\n",
      "\n",
      "    accuracy                           0.66      7500\n",
      "   macro avg       0.60      0.53      0.51      7500\n",
      "weighted avg       0.65      0.66      0.64      7500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 442    7   57   29    2]\n",
      " [ 216   18  179   54    5]\n",
      " [  62    6  372  364   43]\n",
      " [   3    0   72  931  982]\n",
      " [   0    0   14  428 3214]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predictions = torch.max(outputs, dim=1) \n",
    "\n",
    "# Convert predictions and true labels to NumPy arrays\n",
    "y_test_true = y_test_tensor.numpy()  \n",
    "y_test_pred = predictions.numpy()  \n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test_true, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_true, y_test_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
